{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression and Data Analysis in Python\n",
    "This tutorial focuses on some basic tools for regression analysis and data visualization available in Python. The main tools are Pandas and StatsModels. Pandas is a powerful data storage engine built in a combination of C++ (for speed) and Python (for accessiblity). StatsModels is a Python package developed by a group of econometricians that implements a variety of regression and discrete choice models. We will also show some basic plotting functionalities using matplotlib.\n",
    "\n",
    "The dataset used in this tutorial is Q4 bikeshare data for the City of Toronto. We link this data with weather data to provide additional explanatory variables. The data is essentially imported to Python with no pre-processing to show the ability of Python to handle these tasks. We must first import the necessary Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.compat import lzip\n",
    "import seaborn as sns\n",
    "sns.set()  # use Seaborn styles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now import the two datasets from csv files using Pandas. This package can also import STATA, shapefile, and a wide variety of other formats with minimal effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfB = pd.read_csv('./data/2016_Bike_Share_Toronto_Ridership_Q4.csv',sep=',')\n",
    "dfW = pd.read_csv('./data/weather_2016_Q4.csv',sep=',')\n",
    "dfB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfB.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that the 'trip_start_time' column in the bikeshare data does not have a consistent data-time format. We also want to breakup the date and time into components to facilitate easy of data analysis. This could be done in a spreadsheet, but Pandas provides a way to convert the data into a consistent datetime format, even with multiple input datetime formats (as in our case). The same process can be used for the weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfB.loc[:, 'trip_start_time_dt'] = pd.to_datetime(dfB['trip_start_time'], format='mixed')\n",
    "dfB.loc[:, 'trip_stop_time_dt'] = pd.to_datetime(dfB['trip_stop_time'], format='mixed')\n",
    "dfW.loc[:, 'date_time_dt'] = pd.to_datetime(dfW['date_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once thde data are converted to a consistent datetime format, the indivual components can be put in their own columns within the Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfB.loc[:, 'trip_month'] = dfB['trip_start_time_dt'].dt.month\n",
    "dfB.loc[:, 'trip_start_hour'] = dfB['trip_start_time_dt'].dt.hour\n",
    "dfB.loc[:, 'day_of_week'] = dfB['trip_start_time_dt'].dt.dayofweek\n",
    "dfB.loc[:, 'trip_date'] = dfB['trip_start_time_dt'].dt.date\n",
    "dfW.loc[:, 'weather_date'] = dfW['date_time_dt'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas includes a variety of dataframe joining methods. The .merge() function functions similar to a database operation, allowing for left, right, inner, and outer joins. In the next line of code, we join the bikeshare and weather data on the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(dfB, dfW, left_on='trip_date', right_on='weather_date')\n",
    "df = df.dropna(subset=['trip_start_hour','temp','wind_spd'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new dataframe has the following columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic OLS model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing models using StatsModels is quite straightforward. It is made easier using the patsy function syntax used below. This includes the ability to write regression models in standard text using the column names from the dataframe.\n",
    "\n",
    "StatsModels provides an extensive output, including the R-squared, AIC, BIC, and log likelihood. The R-squared in this first model is very low. We can probably do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mod = smf.ols(formula='trip_duration_seconds ~ trip_start_hour + temp + wind_spd', data=df)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The patsy syntax allows us to define categorical variables by simply enclosing a dataframe column name in C(). We include additional user, temporal, and weather data in this model. It is likely that trip length will vary by the weather and user type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mod = smf.ols(formula='trip_duration_seconds ~ C(user_type) + C(day_of_week) + trip_start_hour + temp + wind_spd + rel_hum', data=df)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a better fit, but still not fantastic. We can print statistics on the dataframe using the .describe() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['trip_start_hour'], len(df['trip_start_hour'].unique()), density=True, facecolor='g', alpha=0.75)\n",
    "plt.xlabel('Start Hour');\n",
    "plt.ylabel('Frequency');\n",
    "plt.title('Histogram of Trip Start Hour');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(df['day_of_week'], len(df['day_of_week'].unique()), density=True, facecolor='b', alpha=0.75)\n",
    "plt.xlabel('Day of Week');\n",
    "plt.ylabel('Frequency');\n",
    "plt.title('Histogram of Trip Day');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicollinearity - Condition number\n",
    "One way to assess multicollinearity is to compute the condition number. Values over 20 are worrisome (see Greene 4.9). The first step is to normalize the independent variables to have unit length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['trip_start_hour', 'temp', 'wind_spd', 'rel_hum']\n",
    "X = df.loc[:, names]\n",
    "norm_x = X.values\n",
    "for i, name in enumerate(X):\n",
    "    if name == \"const\":\n",
    "        continue\n",
    "    norm_x[:, i] = X[name] / np.linalg.norm(X[name])\n",
    "norm_xtx = np.dot(norm_x.T, norm_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we take the square root of the ratio of the biggest to the smallest eigen values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs = np.linalg.eigvals(norm_xtx)\n",
    "condition_number = np.sqrt(eigs.max() / eigs.min())\n",
    "print(condition_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems multicollinearity is not an issue here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normality of residuals\n",
    "### Jarque-Bera test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [\"Jarque-Bera\", \"Chi^2 two-tail prob.\", \"Skew\", \"Kurtosis\"]\n",
    "test = sms.jarque_bera(res.resid)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omni test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [\"Chi^2\", \"Two-tail probability\"]\n",
    "test = sms.omni_normtest(res.resid)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residuals are not normally distributed for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heteroskedasticity tests\n",
    "### Breush-Pagan test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [\"Lagrange multiplier statistic\", \"p-value\", \"f-value\", \"f p-value\"]\n",
    "test = sms.het_breuschpagan(res.resid, res.model.exog)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goldfeld-Quandt test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [\"F statistic\", \"p-value\"]\n",
    "test = sms.het_goldfeldquandt(res.resid, res.model.exog)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Breush-Pagan test suggests the residuals are heteroskedastic but the Goldfeld-Quandt suggests they are not. It is not uncommon to get conflicting results from tests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
